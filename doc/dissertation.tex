% Copyright 2009 Wilfred Hughes, CC-BY license
\documentclass[12pt,twoside,notitlepage]{report}

\usepackage{a4}
\usepackage{verbatim}

% for pretty printing grammar in BNF
\usepackage{bnf}

\usepackage{graphicx}

\input{epsf}                            % to allow postscript inclusions
% On thor and CUS read top of file:
%     /opt/TeX/lib/texmf/tex/dvips/epsf.sty
% On CL machines read:
%     /usr/lib/tex/macros/dvips/epsf.tex

\raggedbottom                           % try to avoid widows and orphans
\sloppy
\clubpenalty1000%
\widowpenalty1000%

\addtolength{\oddsidemargin}{6mm}       % adjust margins
\addtolength{\evensidemargin}{-8mm}

\renewcommand{\baselinestretch}{1.1}    % adjust line spacing to make
                                        % more readable
\begin{document}

\bibliographystyle{plain}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Cover sheet


\pagestyle{empty}

\hfill{\LARGE \bf Wilfred Hughes}

\vspace*{60mm}
\begin{center}
\Huge
{\bf oosh: An object oriented shell} \\
\vspace*{5mm}
Computer Science Part II \\
\vspace*{5mm}
Churchill College \\
\vspace*{5mm}
\today  % today's date
\end{center}

\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma, table of contents and list of figures

\setcounter{page}{1}
\pagenumbering{roman}
\pagestyle{plain}

\chapter*{Proforma}

% fixme: wordcount at completion
{\large
\begin{tabular}{ll}
Name:               & \bf Wilfred Hughes                       \\
College:            & \bf Churchill College                     \\
Project Title:      & \bf oosh: An object oriented shell \\
Examination:        & \bf Computer Science Part II, 2009-2010        \\
Word Count:         & \bf 1587 \\
Project Originator: & \bf Wilfred Hughes                    \\
Supervisor:         & \bf David Eyers                    \\ 
\end{tabular}
}

\section*{Original Aims of the Project}
% 72 words
I planned to write a Unix shell from scratch in Python. It would differ from
traditional shells by enforcing a data structure on data piped between processes,
so programs can reason about data at a higher level. It would also enable
transparent network access using a design that can minimise network traffic by
reasoning about the commands used. Finally, the shell syntax would be simplified
to minimise command length for common instructions.

\section*{Work Completed}
% fixme: less than 100 words, but proforma cannot exceed one page
I created an interactive shell with support for both new data-aware commands and
traditional Unix commands. It also offers a basic command history and pretty
prints all structured data.

I created a set of commands which understand the data structure I defined. These
included commands which produce data, commands that manipulate data and an
automatic graphing utility.

For networking I created a server that permits users to log in and execute
commands as if they were being run locally. The client then fetches data lazily
from the server.

\section*{Special Difficulties}
None.
 
\newpage
\section*{Declaration}

I, Wilfred Hughes of Churchill College, being a candidate for Part II
of the Computer Science Tripos, hereby declare that this dissertation
and the work described in it are my own work, unaided except as may be
specified below, and that the dissertation does not contain material
that has already been used to any substantial extent for a comparable
purpose.

\bigskip
\leftline{Signed}

\medskip
\leftline{Date}

\cleardoublepage

\tableofcontents

\listoffigures

\newpage
\section*{Acknowledgements}

% previous projects in this area:
% G Beasley 2003
% J Harbin 2005
% J Tippell 2006 -- Josh (no true pipelines)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% now for the chapters

\cleardoublepage        % just to make sure before the page numbering
                        % is changed

\setcounter{page}{1}
\pagenumbering{arabic}
\pagestyle{headings}

\chapter{Introduction}
% capitalisation conventions: Oosh, Bash, fish
My project was to create a Unix shell from scratch. This gave me the opportunity
to re-evaluate design decisions made by previous shell developers. I therefore
explored a design that made today's common shell tasks easier.

I developed a data format which enforces a tabular structure on data produced by
programs. To demonstrate the versatility of this design I created a number of
programs that could produce or manipulate this data format.

Networking tasks are more common than ever, so my new design needed to include a
convenient networking abstraction. I developed a simple client/server
architecture that uses lazy data transfers to minimise bandwidth.

% overview
% why this solution?


\cleardoublepage

\chapter{Preparation}

\section{Historical Motivations}
The command line shell (henceforth \emph{shell}) is one of the earliest user
interfaces in the history of computing, with recognisable shells having appeared
by 1965 \cite{multics} on the Multics system. A shell offers the user a
convenient abstraction to interact with his system. He may perform common tasks
using considerably shorter commands than using his programming language of
choice. A shell scripting language, therefore, has always been an exchange of
power for brevity.

The original Bourne shell was a product of hacking and experimentation, so was
never formally specified. The most popular successor is Bash, which has pursued
backwards compatibility.

Today's shells are therefore optimised for common use cases that are
outdated. They have ill-specified languages, making it hard for the user to
exercise confidence in preparing scripts---indeed, even implementing
\texttt{sh}-compatible behaviour is non-trivial\cite{bourne}.

I revisited these assumptions. \texttt{who | wc} is not supported by the
original grammar, and pipes are an early (but not an original) feature. How can
I make these commands simpler? What other use cases have emerged since the
original shell formulation?

\section{Existing Solutions}
% feature matrix/table?
I evaluated several well-known shells available today. One of the most popular
options is Bash, which is the default on GNU/Linux and Mac OS X.

A more recent alternative to Bash is the Friendly Interactive Shell (`fish'),
released in 2005. fish is not a substantial departure from Bash, but breaks
backwards compatibility. The design of fish\cite{fishdesign} is motivated by a
desire to create a minimal, orthogonal scripting language. While it achieves
these goals it still requires the user to perform dumb manipulations on
unstructured text.

Another recent development is PowerShell, a Microsoft scripting language and
shell released in 2006. PowerShell is a more radical departure from traditional
shell design, offering an object-oriented approach. Whilst this offers an
increase in expressive power, the PowerShell design does not seek to optimise
the interface for interactive usage. PowerShell cmdlets use a more verbose
noun-verb naming scheme and the programmer is sometimes exposed to underlying
Windows API for simple tasks such as basic networking.

None of these existing solutions have support for transparent
networking. Bash-like shells require the user to {\tt ssh} into the desired
system, so building a pipeline with commands on varying hosts is
non-trivial. PowerShell solutions are more heavyweight and vary for the cmdlet
used. Some commands take a host as an argument whereas others take a network
session object argument.

\section{Requirements}
% pipe saving: users develop iteratively, so let them save output so far. more minimal,
% more hidden, less confusing
I needed to create a shell that would be familiar to an experience shell user,
so my shell should follow shell conventions where sensible. Any shell that hopes
to be be useful for a majority of users must be compatible with existing Unix
commands as there are simply too many to reimplement all of them for a new
design. My shell therefore needed to support the commands already available on
the user's system.

% used a data structure that was line based for compatibility
I also needed to develop a data structure that would enable my programs to
process data at a higher level. With my desire to work with current programs and
aiming to maintain useful shell metaphors, I needed to preserve the concept of a
pipeline as far as possible. This meant local commands needed to use the POSIX
pipe primitive when pipelines were local. Since I wished to support interleaving
of my commands and other commands, I required a data structure that was
transmitted as structured text.

With my data structure in place I needed a set of commands that would
demonstrate the versatility of my design. This set needed to include commands
that would produce structured data, commands that could manipulate this data and
commands that would offer visualisations of this data.

Finally, I wanted my shell to support a convenient network abstraction. This
required a simple client/server architecture and lightweight syntax to support it.

\section{Development Approach}
Since my design aimed to build on traditional shell design, extending an
existing shell was an option worth considering, particularly since most Unix
shells are available under an open-source lincense. I investigated building on
top of Bash or fish, but both of these were substantial pieces of C code, most
of which would require major changes to work with my intended features. I
concluded that starting afresh was my best option.

Since I was developing a tools for a modern Unix system, I chose a workflow that
followed today's Unix coding practices. I chose to write my shell in Python, a
modern scripting language, used Emacs as my editor and used Git, a distributed
version control system to track changes. By the same logic I chose to host my
code on GitHub, which had the additional benefit of acting as an off-site
backup. Later on I needed a parser and lexer so chose Python implementations of
Lex and Yacc as these are also standard tools.

My initial specification was very broad, which enabled me to use a fairly
exploratory style of coding. My final grammar is in figure {\em foo} and was
developed iteratively after researching the syntax used in bash and fish.

Ultimately a mainstream shell is a very large body of code (for example, Bash
4.1 contains over 140,000 lines of C code\footnotemark[1]) and so I could not hope to replicate all
this functionality in the time available. My objective then became to produce a
proof-of-concept shell that demonstrated the advantages of my design.

% in bash directory ran $ find . -name '*.[ch]' | xargs wc -l

\footnotetext[1]{Calculated by running {\tt find . -name '*.[ch]' | xargs wc -l}
  on the source code of Bash 4.1.
}
\stepcounter{footnote}

% features:
% n/w optimisation
% new pipeline metaphor -- save, y-pipe, networking
% strict data format
% interleave new commands
% primitive namespacing
% familiar syntax

% bash and fish: no proper grammar. hard to change guts for more radical
% features, bash substantial body of code -- compatibilty unwanted, no hackable grammar
% python offered cmd.py which is skeleton shell
% networking easier in python, text manipulation particularly so

Typical CLI commands are developed iteratively, which is why commands print
their usage guidelines if used incorrectly. Pipeline saving allows the user to
develop his pipelines more incrementally.

A shell is not as expressive as a programming language (sh was unusual in having
optional ; in its day), and a REPL has a different feel. A shell optimises for
few keystrokes for commands, simple system adminstration tasks, and so on. A
shell has no floating point maths and limited integer support. Almost everything
is exported to invoked processes to handle instead.

% investigation -- compared to existing systems
%   -- bash, fish, powershell, osh (Timoth Budd 1989), REPLs, cmd.exe
%     -- macro language vs programming language
%   -- bash particularly: lex and parse approach, backwards compat
% requirements (from proposal)
% development approach -- development environment, VCS, backup
%   -- system design -- diagrams of structure!
%   -- different implementation approaches considered
%     -- modify existing work, start from scratch
%     -- similar grammar, readily piped to system below?
% theory?
% summary

% quote: The grammar presented in Bourne's paper describing the shell
% distributed with the Seventh Edition of Unix is so far off that it does not
% allow the command who|wc. In fact, as Tom Duff states:

% The POSIX.2 standard includes a yacc grammar that comes close to capturing the
% Bourne shell's behavior, but it disallows some constructs which sh accepts
% without complaint-and there are scripts out there that use them.

\cleardoublepage

\chapter{Implementation}
The final result of my project was the shell client itself, a simple server and
a selection of commands that understood the oosh data structures. I also wrote
some simple scripts to demonstrate the power and flexibility of my design.

(diagram of file layout)

In appendix \ref{examples} I give an example of an Oosh session, which
gives concrete examples and their resulting output. This should clarify how
these techniques work in practice.

\section{Data Structures}
My initial design was to have structured data pass through pipes between the
commands, but this still left me with a variety of implementation
possibilities. The data I wanted to manipulate turned out to fit a tabular
format well, so my iterations focused on a representation of each line of data
with labels. %unclear, clarify

One of the initial ideas was to use an object oriented programming approach, so
my first prototype % tracer code analogy from the pragmatic programmer?
used an object which encapsulated this. However successive refactorings reduced
this object to the point I was able to replace it entirely with Python {\tt
  dict}s (the mapping structure primitive in Python).

My final design separates lines of structured data with the newline character in
the text stream. This enables the interleaving of existing Unix commands and
Oosh commands whilst still preserving the data format. The examples in sections
\ref{lsexample} and \ref{forexample} demonstrate this.

\subsection{Pretty Printing}
Since traditional Unix commands output data in an unstructured way, output forms
vary widely. In contrast, Oosh enforces its format, so it naturally follows to
spend more development time on an attractive pretty print that is run by the
shell on all conformant data.

The pretty print functionality I developed is coloured, uses character-perfect
layout and supports heterogeneous lines of data. This ensures that each column
is printed at optimum width dependent on the length of the
entries. 

The algorithm I designed takes lines of Oosh output as input and finds
the optimum layout. This is $O(C \log C + CL)$ time, where $L$ is the
number of lines, and $C$ the number of columns. I benchmark this
later. %todo: add section number

The disadvantage of my design is that it requires a line entered by
the user to have finished being evaluated before anything is shown to
the user. 

% but by benchmark, even 50k producing data is acceptable
% as discussed later, computational intensive tasks tend not to output
% much to the screen anway

% nice example would be to show that tail does not remove the table header

\subsection{Data Example}
\subsubsection{Raw Data}
% fixme: fix incorrect quoting in output
\begin{verbatim}
{'Owner': 'wilfred', 'Size': 1013234, 'Filename': 'uucp-1.07.tar.gz'}
{'Owner': 'wilfred', 'Size': 1152997, 'Filename': 'fish-1.23.1.tar.gz'}
{'Owner': 'wilfred', 'Size': 1837, 'Filename': 'smlnj.tar.gz'}
{'Owner': 'wilfred', 'Size': 6598300, 'Filename': 'bash-4.1.tar.gz'}
{'Owner': 'wilfred', 'Size': 196529, 'Filename': 'xwrits-2.26.tar.gz'}
{'Filename': 'plasma-weather-0.4.tar.gz', 'Size': 2480099}
\end{verbatim}
Note we have rudimentary types here, distinguishing between strings and
integers. The sort commands in Oosh take advantage of this.

\subsubsection{Pretty Print Output}
% fixme: need to emulate shell colouring
% fixme: discuss character perfect print, unifying disparate data, relation to
% pipe saving
\begin{verbatim}
Filename                         Owner   Size      
uucp-1.07.tar.gz                 wilfred 1013234   
fish-1.23.1.tar.gz               wilfred 1152997   
smlnj.tar.gz                     wilfred 1837      
bash-4.1.tar.gz                  wilfred 6598300   
xwrits-2.26.tar.gz               wilfred 196529    
plasma-weather-0.4.tar.gz        -       2480099
\end{verbatim}

\section{Syntax}
When I developed the first parts of Oosh I did not specify a grammar and simply
modified the syntax that the prototype accepted as I went along. When I
implemented a full interpreter I formalised the syntax I had developed. This
approach enabled me to experiment without having to radically restructure the
code at each iteration.

Oosh supports normal conditionals based on process return codes, two
different types of loops, string variables, pipe variables (which I
refer to as `saved pipes') and command pipelines. This is a smaller
feature set compared with more mature offerings such as Bash and
Fish. However it is sufficient for basic shell interaction, and the
parsing and evaluation code has been written in a sufficiently
flexible manner that any desired expansion could be added with minimal
difficulty.

The design for variables deserves closer attention. The Oosh design
can be seen as two variable namespaces, one that holds strings and the
other that saves the output of pipes. Saved pipes may be emulated in
bash by executing {\tt command1 > /tmp/foo} and then later {\tt command2
  </tmp/foo}. However this approach requires the user to explicitly
create temporary files and does not conveniently generalise to network
access, which requires {\tt scp} as well. Saved pipes are therefore
only a convenience for the user, not a completely novel use case.

Other notable ommissions from this design include subshells (backticks
in Bash usage), arithmetic operations, function definitions, array
variables and non-interactive usage. This turns out to rarely be a
problem for the user. Subshells can be emulated with pipe
saving. Arithmetic operations may be performed using the Unix {\tt bc}
command, which is arguably a more Unix style design (conforming to the
``do one thing and do it well '' design mantra). The remaining
ommissions are more difficult to work around but fall outside of the
use cases being explored in Oosh.

\subsection{Grammar Specification}
\begin{grammar}
      [(colon){$::=$}]
      [(semicolon){$|\,$}]
      [(nonterminal){$\langle$}{$\rangle$}]
      [(quote){}{}] % grim hack since ; has meaning so we use ";"
<commands> : <commands>";" <commands>\\
;commands NAMEDPIPE
;<while>
;<if>
;<assign>
;<for>
;<command>
;$\epsilon$

<for> : for STRING in <values>";" do <commands>";" end

<while> : while <command>";" do <commands>";" end

<if> : if <command>";" do <commands>";" end\\
;if <command>";" do <commands>";" else do <commands>";" end

<assign> : set STRING <value>

<command> : <simplecommand>\\
;NAMEDPIPE <simplecommand>\\
;MULTIPIPE <multicommand> PIPE <simplecommand>\\
;MULTIPIPE <multicommand>

<values> : <value> <values>
;<value>

<value> : STRING
;VARIABLE
;QUOTEDSTRING

<simplecommand> : <values>
;PIPE <simplecommand>
    
<multicommand> : <values>
\end{grammar}

\section{The Shell}
The Oosh client is the largest single piece of code and can function without a
server. Basic command line interaction is provided by the {\tt cmd.Cmd} object
in the standard Python library. This meant the shell had supported basic user
interaction and command history from very early on, allowing me to test the
system as a whole. I was then able to add functionality and complexity
iteratively, with the code largely functional at any given point in time.

The shell itself takes input from the user on a line-by-line basis. Each line is
lexed, parsed and the resulting parse tree is evaluated.

% (simplified) picture of parse tree needed
Within each pipeline % have pipelines been explained by this point?
a {\tt PipePointer} is passed along to abstract away the actual location of the
data. This enables the shell to use Unix pipes locally % would be good to benchmark this
but still move data across the network as needed.

\section{Pipe Saving}
A common way of using today's shells is to iteratively write instructions. A
system administrator, trying to fix a KDE application, may build up a Bash command as
follows:
% fixme: better as figures?
\begin{verbatim}
$ ls /usr/lib
$ diff /backup/20100120/usr/lib /usr/lib
$ diff /backup/20100120/usr/lib /usr/lib | grep libkde
\end{verbatim}

In this example he is repeatedly reading /usr/lib. Each command rereads from
this folder unnecessarily. As the command gets longer he is no longer interested in
the earlier processes. The solution here is to allow him to save this data so
that he can access it again later, whilst only worrying about the current filter
operations he is performing. In Oosh this would become:

\begin{verbatim}
$ oosh_ls /usr/lib |1
$ oosh_ls /backup/20100120/usr/lib |2
$ |1+2 oosh_difference |3
$ |3 grep libkde
\end{verbatim}

The user is now able to reason about previously generated data in a simpler
manner. He can also refer back to previously generated results even if he cannot
generate the data again. Whilst in the first case % or refer to figures
the user can use output redirection to save the output of {\tt ls} and {\tt
  diff}. However the Bash redirection syntax is less concise, so the commands
still cannot be made as short (and therefore as readable) % need to justify
as the Oosh commands.

\section{Networking}
% need intro para

The networking functionality was designed with two intentions: a concise,
convenient syntax and efficient bandwith usage. Today a user can use Bash and
SSH to run commands remotely, but running successive commands on different
systems is not covenient.

% collect data remotely, analyse locally
\begin{verbatim}
home$ ssh wilfred@remote.com
remote$ ps > /tmp/ps.txt
remote$ exit
Connection to remote.com closed.
home$ scp wilfred@remote.com:/tmp/ps.txt .
home$ grep root <ps.txt 
\end{verbatim}

% sadly grep is moved to remote, need better example
\begin{verbatim}
$ connect@remote.com wilfred password
$ ps@remote.com | grep root
\end{verbatim}

After extending the Oosh syntax % nb. not in grammar specification
to allow this simple location specification, I required a server/client
architecture that would enable the user to run remote commands from his Oosh
client as if they were local.

The server is a very simple design, only permitting one user to interact at any
one point. Using the client, the user specifies the location where he wishes
commands to be run. Once the user has logged in to a remote server, the client
will automatically initiate commands on the server. Since the client collects
data on the users behalf we can send the data lazily.

The server supports the following commands:
% would be good to have send to other server


\section{Command Selection}
In addition to the shell with its built-ins, I needed a selection of programs
that understood the structured data and demonstrated its flexibility and
versatility. Clearly with data in a tabular format, a set of commands that offer
database-like commands would be both familiar to the user and powerful. Another
clear advantage of structured data is the ability to draw graphs, so an
automatic graphing facility was created.

I examined the selection of commands offered by BusyBox, as it aims to be a
fairly minimal set of Unix commands required to make a system useful. Many
commands were either interactive, set system settings or started daemons. None
of these programs sent sufficient data to stdout for them to benefit from my
new structured data approach.

There were three types of commands I implemented. I implemented data
sources, which write data to {\tt stdout} in the Oosh data format. I
also implemented data manipulators, which could perform a variety of
database-like manipulations, inspired by the relational calculus. I
also implemented a data analyser that would draw graphs based on input
data given in the Oosh data format.

I named all these commands using an {\tt oosh\_} prefix. This enabled me
to reuse command command names such as {\tt ls} without clashes. This
prefix also acted as a hook to call an Oosh command rather than look
for Unix commands in {\tt \$PATH}.

% fixme: needs to flow into next section

\subsubsection{Data Sources}
I wrote {\tt oosh\_ls}, {\tt oosh\_echo} and {\tt oosh\_ps} based on their
standard Unix equivalents. These produce data that conforms to my data
format and produce interesting, useful data.

\subsubsection{Data Manipulators}
Since my data is a tabular format, I approached data manipulation
using database style operators. Rather than using SQL style operators
(whose syntax differs substantially from that of Oosh) I looked at the
relational algebra and based my operator selection on it.

I wrote {\tt oosh\_select} for selection, {\tt oosh\_project} for
projection, {\tt oosh\_product} for the Cartesian product,
{\tt oosh\_union} for set union, {\tt oosh\_difference} for set difference
and {\tt oosh\_rename} for attribute rename. This is the minimal subset
needed to give the user full expressive power. I also added
{\tt oosh\_sort}, a sort operator as this is a common shell task that
benefits substantially from structured data.

\subsubsection{Data Analyser}
The pretty print I wrote is a great improvement over the simplistic
line-by-line printing used by traditional shell commands. However once
we have pervasive metadata being produced we can perform more
sophisticated analyses of the data. I wrote a graphing utility that
takes full advantage of this structure.

My grapher, {\tt oosh\_graph}, simply requires the user to name the
dataseries he wishes to plot and the type of graph he wants. This is
not impossible in Bash, but Oosh enables a more elegant approach since
he can describe the data in a higher-order fashion.

\begin{figure}[h]
  \caption{A pie chart generated with {\tt oosh\_ps | oosh\_graph pie Command `CPU \%' cpu\_consumption.svg}}
  \centering
  \includegraphics[scale=0.4]{cpu_consumption.png}
\end{figure}

\section{Problems Overcome}

The largest problem I faced during coding was dealing with the limited
specification I started with. I could not implement a scripting
language for Oosh until I had a grammar, which required careful and
subjective judgements.

My language choice of Python proved to be a good decision, but was not
without problems. I made the decision to use Python 3, which
drastically limited the number of third-party libraries I could
use. Since each command is spawned as a separate process I was able to
use Python 2 where it was absolutely necessary by hard-coding these
exceptions. This was not ideal since my resulting codebase became
heterogeneous.

Python's documentation is generally good, but I did encounter bugs. I
worked around these by examining the source of the libraries I was
using (a luxury not always present in compiled languages).

Unix shells have been around for so long that they have acquired a lot
of tradition and legacy behaviour. Some of these legacy traits caused
problems for me, particularly escape codes. Today's shells still
support escape codes for obsolete behaviour such as ringing the system
bell. These characters caused crashes in bugs, but could not be
printed to the string, so presented an unusual challenge for finding
the bug.

The other limitation I encountered was Python's handling of signals,
which is limited. Spawning subprocesses requires the ability to emit
and receive a number of interprocess signals, and the Python base
libraries do not support {\tt SIGPIPE}. I was only partly able to work
around this limitation, and there still exist corner cases where Oosh
crashes on large inputs. The correct way to fix it would be to replace
a number of library functions with equivalents that handle this
signal, but I concluded this was too time consuming for a rare bug.

\cleardoublepage

\chapter{Evaluation}
To evaluate the expressive power of commands within Oosh, I have prepared a
selection of character count comparisons. I also include some data on the
number of processes spawned between a typical Bash command and a typical Oosh
command.

I have also collected a set of networking benchmarks, which measure the
effectiveness of my bandwidth optimisations versus a na\"{i}ve implementation. I
measure both networking overhead and scaling.

Finally, I also include some simple performance benchmarks based on system
resource consumption and latency from the user's perspective.

\section{Character Counts}

\section{Network Benchmarks}

\section{Bash Overheads}


% what was evaluated?
% what were the results?
%   -- no of processes spawned
%   -- length of equivalent bash shells (can use old commands still!)
%   -- network data comparisons (fixed and variable cost increases measured)
%   -- performance
%     -- wall clock time
%     -- memory and CPU usage (never exceeded 43MiB memory during
%     benchmarks, or 40% CPU)
% testing/debugging
% comparing against requirements

\cleardoublepage
\chapter{Conclusions}

% aims again
% accomplishments -- likes, dislikes, results
% hindsight thoughts -- better approaches
% future prospects

Characterising typical shell usage is difficult. I believe I created a
compelling product. Ultimately very complex shell interactions are often moved
to standalone applications. % contrast Gentoo's build scripts, a distro (Debian?)
                           % moving to C init scripts

The shell is used for quick and dirty tasks, collecting debugging output, simple
file manipulations. Spawning processes ({\tt /etc/init.d/apache start}) and
hardware configuration ({\tt ifconfig}) are also common shell usages which
neither networking convenience or structured data can offer any great
improvement on. Pervasive use of this data structure would offer more
interesting usages, one good example being the {\tt /sys} directory. Tab
completion would be another interesting area to explore, since commands can know
column names (e.g. column name tab completion on oosh\_sort). To be used in
production, Oosh would need to have the remaining shell features added, such as
regular expression support (easy exercise given Python's support). Subshells and
subcommands would be useful to a real user, though not adding anything to the
proof-of-concept design.

% also problems with some data simply not being structured: apt-get upgrade,
% wget, sophisticated interfaces: nano, emacs, irssi, lynx
% line continuations would be nice too

\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography

\addcontentsline{toc}{chapter}{Bibliography}
\begin{thebibliography}{5} % at most 5 citations

\bibitem{multics}
  Louis Pouzin
  \emph{Multics: The Origin of the Shell}
  http://www.multicians.org/shell.html

\bibitem{bourne}
  Tom Duff
  \emph{Rc -- A Shell for Plan 9 and UNIX systems}
  http://doc.cat-v.org/plan\_9/4th\_edition/papers/rc

\bibitem{fishdesign}
  Axel Liljencrantz
  \emph{Design Document}
  http://fishshell.org/user\_doc/design.html

\end{thebibliography}
\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the appendices
\appendix

\chapter{Example Usage}
\label{examples}
% populated from src/examples.txt

\section{Simple Pipeline}
\label{lsexample}
A simple pipeline showing contextual data manipulation. Note tail is a part of
GNU coreutils and is working in Oosh without modification.
\begin{verbatim}
1$ oosh_ls /usr/bin | oosh_project Filename Size | oosh_sort Size | tail
Filename Size
mencoder 10984340
inkview  11074508
inkscape 11100236
mplayer  11758932
bibtexu  17312116
xetex    17799216
xelatex  17799216
skype    18567888
\end{verbatim}

\section{Networking}
Connect to a server, run commands on it as if they are local commands. Also
demonstrates reuse of semicolon for command sequences as found on other common
shells.
\begin{verbatim}
2$ connect@193.60.95.74 wilfred mypassword;
     oosh_ls@193.60.95.74 /home/wilfred/logs | grep kde
Filename               Owner   Size
freenode_#kde-i18n.log wilfred 879
freenode_#kde.log      wilfred 53318
\end{verbatim}

Note grep is run on the server despite not specifying. Also note the
output of {\tt oosh\_ls} is not sent immediately, the client only
requests it to be sent at the end.

\begin{verbatim}
$ ./ooshserver.py
Starting server at soup.linux.pwf.cam.ac.uk (193.60.95.74) on port 12345
request is ['connect', 'wilfred', mypassword']
request is ['command', 'python3', 'oosh_ls.py', '/home/wilfred/logs']
request is ['command', 'grep', 'kde']
request is ['send']
\end{verbatim}

\section{Control structures}
\label{forexample}
An example of the familiar command structures available in Oosh. The {\tt for}
loop syntax is based on that of fish.
\begin{verbatim}
3$ for x in 131.111.8.42 131.111.12.20 131.111.131.1; do ping $x -c 1; end
PING 131.111.8.42 (131.111.8.42) 56(84) bytes of data.
64 bytes from 131.111.8.42: icmp_seq=1 ttl=252 time=0.400 ms

--- 131.111.8.42 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 0.400/0.400/0.400/0.000 ms
PING 131.111.12.20 (131.111.12.20) 56(84) bytes of data.
64 bytes from 131.111.12.20: icmp_seq=1 ttl=252 time=0.433 ms

--- 131.111.12.20 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 0.433/0.433/0.433/0.000 ms
PING 131.111.131.1 (131.111.131.1) 56(84) bytes of data.
64 bytes from 131.111.131.1: icmp_seq=1 ttl=63 time=0.338 ms

--- 131.111.131.1 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 0.338/0.338/0.338/0.000 ms
\end{verbatim}

\section{Multi-way Pipes}
Here we see an example of pipelines being saved. We also see an Oosh command
that takes multiple input pipes.
\begin{verbatim}
4$ oosh_ps |1; sleep 1m; oosh_ps |2; |1+2 oosh_difference
Command CPU % Memory % PID  User
python3 0.0   0.3      6081 wilfred
sh      0.0   0.0      6082 wilfred
ps      0.0   0.0      6083 wilfred
\end{verbatim}

\chapter{References}

\chapter{Project Proposal}
% assumes we are compiling the dissertation using makepdf.sh
% use same formatting as proposal had in header
\parindent 0pt
\parskip 6pt
\include{proposal_include}

\end{document}
